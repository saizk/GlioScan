{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyOfAmaAkqE5"
   },
   "source": [
    "# **IDH Classification for Gliomas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0kguWc8k1va"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2FqN0iDkye8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMgZUsLekqE7"
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0PkE0SDkvPg"
   },
   "outputs": [],
   "source": [
    "!pip install monai\n",
    "!pip install wandb\n",
    "!pip install pytorch-ignite  # optional\n",
    "!pip install transformers  # optional\n",
    "!pip install einops\n",
    "!pip install pydantic==1.10.11\n",
    "!pip install lightning\n",
    "# !pip install SimpleITK  # optional\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu9KgEMAkqE8"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuL9SBT3kqE8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "import shutil\n",
    "import logging\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader# as TorchDataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.config import print_config\n",
    "from monai.data import ImageDataset#, DataLoader\n",
    "\n",
    "\n",
    "pin_memory = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NBGUdPbOlDU"
   },
   "outputs": [],
   "source": [
    "ROOT = 'drive/MyDrive/Proyecto Gliomas'\n",
    "os.chdir(ROOT)\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "priS60P8kqE8"
   },
   "outputs": [],
   "source": [
    "GM_ROOT = f'data/Gregorio-Marañón'\n",
    "UCSF_ROOT = f'data/TCIA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds59O4ov9aYp"
   },
   "outputs": [],
   "source": [
    "GM_DIR = f'{GM_ROOT}/GM-BRATS+HM+NORM+CROPPED-NPZ'\n",
    "UCSF_DIR = f'{UCSF_ROOT}/UCSF-NORM-LIGHT-CROPPED-NPZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgcmG--nlQaE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'participants.csv', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRCgY_D6PXq8"
   },
   "outputs": [],
   "source": [
    "def get_path(participant_id, database, modality, format_='nii.gz'):\n",
    "    path = None\n",
    "    if database == 'TCIA':\n",
    "        path = f'{UCSF_DIR}/{participant_id}/anat/{participant_id}_{modality}.{format_}'\n",
    "    elif database == 'GM':\n",
    "        path = f'{GM_DIR}/{participant_id}/anat/{participant_id}_{modality}.{format_}'\n",
    "    # assert os.path.exists(path), path\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h3mD2IrlmBM"
   },
   "source": [
    "## Setup Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoAKzihER4V9"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = (240, 240, 155)  # original TCIA image size\n",
    "IMG_SIZE = (128, 128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6cEwKwQQA82"
   },
   "outputs": [],
   "source": [
    "df['T1w_ce_path'] = df.apply(lambda x: get_path(x['participant_id'], x['database'], 'ce-GADOLINIUM_T1w', 'npz'), axis=1)\n",
    "df['FLAIR_path'] = df.apply(lambda x: get_path(x['participant_id'], x['database'], 'FLAIR', 'npz'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTVC9fh5SE7W"
   },
   "outputs": [],
   "source": [
    "images = np.array([[path] for path in df['T1w_ce_path']])\n",
    "# images = np.array([[path] for path in df['FLAIR_path']])\n",
    "\n",
    "images = np.array(list(zip(df['T1w_ce_path'], df['FLAIR_path'])))\n",
    "# images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXsEjq0QlhHy"
   },
   "source": [
    "## Setup Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGLcs9j-urth"
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels_):  # unused\n",
    "    mapping = {\n",
    "        (0, 0): 0,\n",
    "        (1, 0): 1,\n",
    "        (1, 1): 2,\n",
    "        # (0, 1): 3,\n",
    "    }\n",
    "    # Use a list comprehension to map each row of the array\n",
    "    return np.array([mapping[tuple(row)] for row in labels_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luT2SutckqE8"
   },
   "outputs": [],
   "source": [
    "# Sample labels for multi-class classification using binary pairs:\n",
    "labels = np.array(list(df['idh_status']))\n",
    "# labels = np.array(list(df['codeletion_1p19q_status']))\n",
    "\n",
    "# labels = np.array(list(zip(df['idh_status'], df['codeletion_1p19q_status'])))\n",
    "# labels = encode_labels(labels)\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9v5GvS5StI-e"
   },
   "outputs": [],
   "source": [
    "no_labels = len(np.unique(labels))\n",
    "print(no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDqAYSZtp6RY"
   },
   "outputs": [],
   "source": [
    "# labels = torch.nn.functional.one_hot(torch.as_tensor(labels)).float()\n",
    "# labels[0], labels[2], labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44dW2w-zR4Hf"
   },
   "source": [
    "#### [0, 0] --> IDH negative without codeletion\n",
    "#### [0, 1] --> IDH negative with codeletion\n",
    "#### [1, 0] --> IDH positive without codeletion\n",
    "#### [1, 1] --> IDH positive with codeletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBW992OjlZuK"
   },
   "source": [
    "## Setup Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_feature_vector(numerical_features, categorical_features):\n",
    "    # Normalize age\n",
    "    scaler = StandardScaler().fit(np.array(*numerical_features).reshape(-1, 1))\n",
    "    normalized_features = scaler.transform(np.array(*numerical_features).reshape(-1, 1))\n",
    "\n",
    "    # One-hot encode sex, grade, and histologic_subtype\n",
    "    encoder = OneHotEncoder(sparse_output=False).fit(np.column_stack(categorical_features))\n",
    "    encoded_features = encoder.transform(np.column_stack(categorical_features))\n",
    "\n",
    "    # Create single feature vector by concatenating normalized age with other encoded features\n",
    "    feature_vector = np.hstack([normalized_features, encoded_features])\n",
    "    return feature_vector"
   ],
   "metadata": {
    "id": "6d_W0dvP0iwu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39NI9AcwO2hc"
   },
   "outputs": [],
   "source": [
    "ages, sexes, grades = df['age'], df['sex'], df['who_cns_grade']\n",
    "\n",
    "numerical_features = [ages]\n",
    "categorical_features = [sexes]\n",
    "# categorical_features = [sexes, grades]\n",
    "\n",
    "feature_vector = get_feature_vector(numerical_features, categorical_features)\n",
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Data Splitting**"
   ],
   "metadata": {
    "id": "7QyXvYXY8tme"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "random_state = 42\n",
    "\n",
    "train_size = 0.8\n",
    "test_size = 1.0 - train_size  # 0.2\n",
    "val_size = 0.25"
   ],
   "metadata": {
    "id": "jhzVlO6TWB_7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def split_indices(df_ids, test_size=0.2, val_size=0.25, random_state=42):\n",
    "    train_ids_, test_ids_ = train_test_split(df_ids, test_size=test_size, random_state=random_state)\n",
    "    train_ids_, val_ids_ = train_test_split(train_ids_, test_size=val_size, random_state=random_state)\n",
    "    return train_ids_, val_ids_, test_ids_\n",
    "\n",
    "def split_by_idh(df, idh_column='idh_status', test_size=0.2, val_size=0.25, random_state=42):\n",
    "    idh_neg_ids = df[df[idh_column] == 0].index.to_numpy()\n",
    "    idh_pos_ids = df[df[idh_column] == 1].index.to_numpy()\n",
    "    train_idh_neg_ids, val_idh_neg_ids, test_idh_neg_ids = split_indices(idh_neg_ids, test_size=test_size, val_size=val_size, random_state=random_state)\n",
    "    train_idh_pos_ids, val_idh_pos_ids, test_idh_pos_ids = split_indices(idh_pos_ids, test_size=test_size, val_size=val_size, random_state=random_state)\n",
    "\n",
    "    print(f'IDH Negative --> Train: {len(train_idh_neg_ids)} / Validation: {len(val_idh_neg_ids)} / Test: {len(test_idh_neg_ids)}')\n",
    "    print(f'IDH Positive --> Train: {len(train_idh_pos_ids)} / Validation: {len(val_idh_pos_ids)} / Test: {len(test_idh_pos_ids)}')\n",
    "\n",
    "    train_ids = np.concatenate((train_idh_neg_ids, train_idh_pos_ids), axis=0)\n",
    "    val_ids = np.concatenate((val_idh_neg_ids, val_idh_pos_ids), axis=0)\n",
    "    test_ids = np.concatenate((test_idh_neg_ids, test_idh_pos_ids), axis=0)\n",
    "    return train_ids, val_ids, test_ids"
   ],
   "metadata": {
    "id": "ax7L8adb836M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gm_df = df[df['database'] == 'GM']\n",
    "gm_train_ids, gm_val_ids, gm_test_ids = split_by_idh(gm_df, test_size=test_size, val_size=val_size, random_state=random_state)\n",
    "\n",
    "print(f'GM Database --> Train: {len(gm_train_ids)} / Validation: {len(gm_val_ids)} / Test: {len(gm_test_ids)}')\n",
    "assert len(gm_train_ids) + len(gm_val_ids) + len(gm_test_ids)  == len(gm_df)  # 40"
   ],
   "metadata": {
    "id": "c0JsZVFKT6Hr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tcia_df = df[df['database'] == 'TCIA']\n",
    "tcia_train_ids, tcia_val_ids, tcia_test_ids = split_by_idh(tcia_df, test_size=test_size, val_size=val_size, random_state=random_state)\n",
    "\n",
    "print(f'TCIA Database --> Train: {len(tcia_train_ids)} / Validation: {len(tcia_val_ids)} / Test: {len(tcia_test_ids)}')\n",
    "assert len(tcia_train_ids) + len(tcia_val_ids) + len(tcia_test_ids)  == len(tcia_df)  # 494"
   ],
   "metadata": {
    "id": "tWUGPelDYqYc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_ids = np.concatenate((gm_train_ids, tcia_train_ids), axis=0)\n",
    "val_ids = np.concatenate((gm_val_ids, tcia_val_ids), axis=0)\n",
    "test_ids = np.concatenate((gm_test_ids, tcia_test_ids), axis=0)\n",
    "\n",
    "print(f'TOTAL --> Train: {len(train_ids)} / Validation: {len(val_ids)} / Test: {len(test_ids)}')"
   ],
   "metadata": {
    "id": "tWT3oISHWSwA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "s1, s2, s3 = set(train_ids), set(val_ids), set(test_ids)\n",
    "assert not (s1 & s2 or s1 & s3 or s2 & s3)  # Assert that indices have no common values"
   ],
   "metadata": {
    "id": "9sjgCSw5YCyc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_imgs, train_labels, train_feature_vector = images[train_ids], labels[train_ids], feature_vector[train_ids]\n",
    "val_imgs,   val_labels,   val_feature_vector   = images[val_ids],   labels[val_ids],   feature_vector[val_ids]\n",
    "test_imgs,  test_labels,  test_feature_vector  = images[test_ids],  labels[test_ids],  feature_vector[test_ids]"
   ],
   "metadata": {
    "id": "AKXSneyd7TTI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gm_test_imgs,   gm_test_labels,   gm_test_features   = images[gm_test_ids],   labels[gm_test_ids],   feature_vector[gm_test_ids]\n",
    "tcia_test_imgs, tcia_test_labels, tcia_test_features = images[tcia_test_ids], labels[tcia_test_ids], feature_vector[tcia_test_ids]"
   ],
   "metadata": {
    "id": "Gg5OMUGu7KTx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z12vrJlqm9HN"
   },
   "source": [
    "## **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps9oYsgFhm49"
   },
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    NormalizeIntensity,\n",
    "    Compose,\n",
    "    CropForeground,\n",
    "    RandRotate90,\n",
    "    RandZoom,\n",
    "    RandAffine,\n",
    "    RandScaleIntensity,\n",
    "    RandShiftIntensity,\n",
    "    RandGaussianNoise,\n",
    "    RandAdjustContrast,\n",
    "    RandGaussianSharpen,\n",
    "    RandKSpaceSpikeNoise,\n",
    "    ToTensor\n",
    ")\n",
    "\n",
    "spatial_transforms = Compose([\n",
    "    CropForeground(select_fn=lambda x: x > 1, margin=10),\n",
    "    RandRotate90(prob=0.25, spatial_axes=[0, 1]),    # Random 90-degree rotation\n",
    "    RandRotate90(prob=0.25, spatial_axes=[1, 2]),    # Random 90-degree rotation\n",
    "    RandZoom(prob=0.3, min_zoom=(1.0, 1.0), max_zoom=(1.2, 1.2)),\n",
    "    RandAffine(                                      # Elastic deformation & rotation\n",
    "        prob=0.25,\n",
    "        rotate_range=(0, 0, np.pi/8),\n",
    "        shear_range=(0.1, 0.1, 0.1),\n",
    "        spatial_size=IMG_SIZE\n",
    "    )\n",
    "])\n",
    "\n",
    "intensity_transforms_t1 = Compose([\n",
    "    RandScaleIntensity(prob=0.5, factors=(0.8, 1.2)),   # Random intensity scaling for T1\n",
    "    RandShiftIntensity(prob=0.5, offsets=(-20, 20)),\n",
    "    RandAdjustContrast(prob=0.5, gamma=(0.9, 1.1)),\n",
    "    RandGaussianSharpen(prob=0.3),\n",
    "    RandGaussianNoise(prob=0.2, mean=0, std=0.1),       # Gaussian Noise for T1\n",
    "    RandKSpaceSpikeNoise(prob=0.2)\n",
    "])\n",
    "intensity_transforms_flair = Compose([\n",
    "    RandScaleIntensity(prob=0.5, factors=(0.7, 1.3)),   # Random intensity scaling for FLAIR\n",
    "    RandShiftIntensity(prob=0.5, offsets=(-20, 20)),\n",
    "    RandAdjustContrast(prob=0.5, gamma=(0.9, 1.1)),\n",
    "    RandGaussianSharpen(prob=0.3),\n",
    "    RandGaussianNoise(prob=0.2, mean=0, std=0.1),       # Gaussian Noise for FLAIR\n",
    "    RandKSpaceSpikeNoise(prob=0.2)\n",
    "])\n",
    "\n",
    "intensity_transforms = [\n",
    "    intensity_transforms_t1,\n",
    "    intensity_transforms_flair\n",
    "]\n",
    "\n",
    "val_transforms = Compose([\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Validation**"
   ],
   "metadata": {
    "id": "7ftDThDa8pJc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mw8twlHhMvZL"
   },
   "outputs": [],
   "source": [
    "def validate(fabric, model, val_loader, epoch):\n",
    "    \"\"\"\n",
    "    Validate a binary classification model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: PyTorch model object.\n",
    "    - dataloader: DataLoader for the validation dataset.\n",
    "\n",
    "    Returns:\n",
    "    - Average loss, accuracy, precision, recall, and F1-score on the validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            *_, labels = batch\n",
    "            loss, predictions, probs = model.validation_step(batch, i)\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            print(f\"Validating batch {i + 1}/{len(val_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    average_loss = total_loss / len(val_loader)\n",
    "    accuracy_ = accuracy_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Validation finished. Average Loss: {average_loss:.4f}\\tAccuracy: {accuracy_:.4f}\")\n",
    "    wandb.log({\n",
    "        \"val/epoch\": epoch,\n",
    "        \"val/loss\": average_loss,\n",
    "        \"val/accuracy\": accuracy_,\n",
    "        \"val/roc_auc\": roc_auc\n",
    "    })\n",
    "    return average_loss, accuracy_"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Training**"
   ],
   "metadata": {
    "id": "Zmmol5iP8mMl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from classification.model import LitModel\n",
    "from classification.early_stopper import EarlyStopper\n",
    "from classification.nets import EnhancedAttentionUnet, EnhancedDenseNet, EnhancedHighResNet, EnhancedResNet, EnhancedUNET, EnhancedUNETR, EnhancedVarAutoEncoder, EnhancedViT, EnhancedViTAutoEnc, EnhancedVNet"
   ],
   "metadata": {
    "id": "hNIVY1fH9yoD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9blQgaMlkqE9"
   },
   "outputs": [],
   "source": [
    "def train(fabric, model, train_loader, val_loader, optimizer, scheduler, model_name='model.pth'):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    best_accuracy_epoch = -1\n",
    "    best_accuracy = -1\n",
    "\n",
    "    n_steps_per_epoch = np.ceil(len(train_loader.dataset) / model.batch_size)\n",
    "\n",
    "    for epoch in range(model.num_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"Epoch {epoch + 1}/{model.num_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.training_step(batch, batch_idx)\n",
    "            fabric.backward(loss)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(f\"{batch_idx + 1}/{int(n_steps_per_epoch)}, Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        if scheduler:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "        wandb.log({\n",
    "            'train/epoch': epoch,\n",
    "            'train/loss': epoch_loss\n",
    "        })\n",
    "\n",
    "        if (epoch + 1) % model.val_interval != 0:\n",
    "            continue\n",
    "\n",
    "        # VALIDATION\n",
    "        avg_val_loss, accuracy = validate(fabric, model, val_loader, epoch)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_accuracy_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "            print(\"Saved new best metric model\")\n",
    "\n",
    "        print(f\"Best accuracy: {best_accuracy:.4f} at epoch {best_accuracy_epoch}\")\n",
    "\n",
    "        should_stop = early_stop_callback.on_validation_end(avg_val_loss)\n",
    "        print(f'Patience: {early_stop_callback.patience}')\n",
    "        if should_stop:\n",
    "            break\n",
    "\n",
    "    print(f\"Training completed, best_accuracy: {best_accuracy:.4f} at epoch: {best_accuracy_epoch}\")\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1gd4lg5tQt9"
   },
   "outputs": [],
   "source": [
    "spatial_dims = 3  # 3D spatial dimensions\n",
    "in_channels = 2  # 1 for each sequence (T1CE + FLAIR)\n",
    "out_channels = 1  # 1 for binary classification 0 | 1\n",
    "feature_dim = feature_vector.shape[1]  # 3\n",
    "feature_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zE33Td5BJABE"
   },
   "outputs": [],
   "source": [
    "def get_model(model, in_channels, out_channels, feature_dim, config):\n",
    "    if model == 'AttentionUnet':\n",
    "        net = EnhancedAttentionUnet(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            channels=(16, 32, 64),\n",
    "            strides=(2, 2, 2),\n",
    "            feature_dim=feature_dim\n",
    "        )\n",
    "        config[\"batch_size\"] = 8\n",
    "    elif model == 'DenseNet':\n",
    "        net = EnhancedDenseNet(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            feature_dim=feature_dim\n",
    "        )\n",
    "        config[\"batch_size\"] = 32\n",
    "    elif model == 'HighResNet':\n",
    "        net = EnhancedHighResNet(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            feature_dim=feature_dim,\n",
    "        )\n",
    "        config[\"batch_size\"] = 2\n",
    "\n",
    "    elif model == 'ResNet':\n",
    "        net = EnhancedResNet(\n",
    "            spatial_dims=spatial_dims,\n",
    "            n_input_channels=in_channels,\n",
    "            feature_dim=feature_dim,\n",
    "            block='basic',\n",
    "            layers=[3, 4, 6, 3],\n",
    "            block_inplanes=[64, 128, 256, 512],\n",
    "            conv1_t_stride=2,\n",
    "            num_classes=out_channels,\n",
    "        )\n",
    "        # config[\"batch_size\"] = 2\n",
    "    elif model == 'UNET':\n",
    "        net = EnhancedUNET(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            feature_dim=feature_dim,\n",
    "            channels=(4, 8, 16, 32, 64),\n",
    "            strides=(2, 2, 2, 2),\n",
    "        )\n",
    "        config[\"batch_size\"] = 128\n",
    "    elif model == 'UNETR':\n",
    "        net = EnhancedUNETR(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            img_size=IMG_SIZE,\n",
    "            spatial_dims=spatial_dims,\n",
    "            feature_dim=feature_dim\n",
    "        )\n",
    "        config[\"batch_size\"] = 8\n",
    "    elif model == 'VarAutoEncoder':\n",
    "        net = EnhancedVarAutoEncoder(\n",
    "            spatial_dims=spatial_dims,\n",
    "            feature_dim=feature_dim,\n",
    "            in_shape=(2, *IMG_SIZE),\n",
    "            out_channels=out_channels,\n",
    "            latent_size=3,\n",
    "            channels=(8, 16, 32, 64),\n",
    "            strides=(1, 2, 2, 2),\n",
    "        )\n",
    "        config[\"batch_size\"] = 32\n",
    "    elif model == 'ViT':\n",
    "        net = EnhancedViT(\n",
    "            spatial_dims=spatial_dims,\n",
    "            img_size=IMG_SIZE,\n",
    "            in_channels=in_channels,\n",
    "            num_classes=out_channels,\n",
    "            patch_size=(16, 16, 16),\n",
    "            hidden_size=768,\n",
    "            mlp_dim=3072,\n",
    "            feature_dim=feature_dim,\n",
    "            classification=True\n",
    "        )\n",
    "        config[\"batch_size\"] = 8\n",
    "    elif model == 'VitAutoEnc':\n",
    "        net = EnhancedViTAutoEnc(\n",
    "            img_size=IMG_SIZE,\n",
    "            patch_size=(16, 16, 16),\n",
    "            hidden_size=768,\n",
    "            deconv_chns=16,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            feature_dim=feature_dim\n",
    "        )\n",
    "        config[\"batch_size\"] = 64\n",
    "    elif model == 'VNet':\n",
    "        net = EnhancedVNet(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            feature_dim=feature_dim\n",
    "        )\n",
    "        config[\"batch_size\"] = 8\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model name: ')\n",
    "\n",
    "    model_ = LitModel(model=net, **config)\n",
    "    model_.name = model\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KK8pbrp3KJ5b"
   },
   "outputs": [],
   "source": [
    "fabric = L.Fabric(\n",
    "    accelerator='cuda', devices=1,\n",
    "    strategy=\"auto\",\n",
    "    # callbacks=[early_stop_callback],\n",
    ")\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWpEMm6WKxFh"
   },
   "outputs": [],
   "source": [
    "MODEL = 'DenseNet'\n",
    "NUM_EPOCHS = 100\n",
    "LOSS_FUNCTION = nn.BCEWithLogitsLoss()  # nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwrR-xtkR_ky"
   },
   "outputs": [],
   "source": [
    "KEY = 'YOUR_WANDB_KEY'\n",
    "wandb.login(key=KEY)\n",
    "wandb_logger = wandb.init(project=\"idh-status\")#, name=f'{MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 16,\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    \"lr\": 1e-4,\n",
    "    'loss_func': LOSS_FUNCTION,\n",
    "    \"val_interval\": 1,\n",
    "}"
   ],
   "metadata": {
    "id": "rYITtWdFuw_S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0MM_bI6rxMJ"
   },
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    MODEL,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    feature_dim=feature_dim,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIiJax1HZSMk"
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopper(\n",
    "    stopping_threshold=0.05,\n",
    "    patience=10\n",
    ")\n",
    "# model.early_stop = early_stop_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhTjR4WHwG2a"
   },
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "\n",
    "train_loader = model.train_dataloader(\n",
    "    train_imgs, train_labels, train_feature_vector,\n",
    "    num_workers=num_workers,\n",
    "    spatial_transforms=spatial_transforms,\n",
    "    intensity_transforms=intensity_transforms\n",
    ")\n",
    "val_loader = model.val_dataloader(\n",
    "    val_imgs, val_labels, val_feature_vector,\n",
    "    num_workers=num_workers,\n",
    "    transforms=val_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YCj8-4bWtOA"
   },
   "outputs": [],
   "source": [
    "model_name = f'models/{MODEL.lower()}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6v8vmBEEhsx1"
   },
   "outputs": [],
   "source": [
    "optimizer = model.configure_optimizers()\n",
    "\n",
    "model_, optimizer = fabric.setup(model, optimizer)\n",
    "train_loader, val_loader = fabric.setup_dataloaders(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oqs7euHtcKpZ"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, verbose=True)\n",
    "# scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzliR_5p1hNI"
   },
   "outputs": [],
   "source": [
    "best_accuracy = train(\n",
    "    fabric, model_,\n",
    "    train_loader, val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Testing**"
   ],
   "metadata": {
    "id": "b7isyTKT8buF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aN9IlUoVWXG"
   },
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load the model checkpoint from the given path.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_probs_by_class(probs):\n",
    "    probs = np.array(probs)[:, 0]\n",
    "    all_probs_neg = np.where(probs >= 0.5, 1 - probs, probs)\n",
    "    all_probs_pos = 1 - all_probs_neg\n",
    "    return np.column_stack((all_probs_neg, all_probs_pos))\n",
    "\n",
    "\n",
    "def test_model(fabric, model, test_loader):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Store all predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    verbose = test_loader.dataset.verbose\n",
    "\n",
    "    # No gradient computation\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if verbose:\n",
    "                name = batch.pop()\n",
    "            preds, probs, labels = model.test_step(batch, i)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            print(f'Testing batch {i + 1}/{len(test_loader)}')\n",
    "            if verbose:\n",
    "                print(f'Name: {name} --> Label: {int(labels.cpu().numpy()[0])} / Pred: {int(preds.cpu().numpy()[0][0])}')\n",
    "\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy_ = accuracy_score(all_labels, all_preds)\n",
    "    precision_ = precision_score(all_labels, all_preds)\n",
    "    recall_ = recall_score(all_labels, all_preds)\n",
    "    f1_score_ = f1_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    # Get detailed classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=['IDH-Neg', 'IDH-Pos'])\n",
    "\n",
    "    # split_probs = split_probs_by_class(all_probs)\n",
    "\n",
    "    print(f\"Overall Accuracy: {accuracy_ * 100:.2f}%\")\n",
    "    print(f\"Overall Precision: {precision_ * 100:.2f}%\")\n",
    "    print(f\"Overall Recall: {recall_ * 100:.2f}%\")\n",
    "    print(f\"Overall F1 Score: {f1_score_ * 100:.2f}%\")\n",
    "    print(f\"Overall ROC-AUC: {roc_auc * 100:.2f}%\")\n",
    "\n",
    "    test_metrics = {\n",
    "        f\"test/{model.name}_accuracy\": accuracy_,\n",
    "        f\"test/{model.name}_precision\": precision_,\n",
    "        f\"test/{model.name}_recall\": recall_,\n",
    "        f\"test/{model.name}_f1_score\": f1_score_,\n",
    "        f\"test/{model.name}_roc_auc\": roc_auc,\n",
    "        # f\"test/{model.name}_roc_auc_plot\": wandb.plot.roc_curve(all_labels, split_probs, labels=['IDH-Neg', 'IDH-Pos']),\n",
    "        f\"test/{model.name}_confusion_matrix\": wandb.sklearn.plot_confusion_matrix(\n",
    "            all_labels, all_preds, ['IDH-Neg', 'IDH-Pos']\n",
    "        )\n",
    "    }\n",
    "    return test_metrics, report"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "DenseNet --> 6 features (age, sex, grades)\n",
    "\n",
    "HighResNet --> 6 features (age, sex, grades)\n",
    "\n",
    "AttentionUnet --> 3 features (age, sex)\n",
    "\n",
    "VitAutoEnc --> 6 features (age, sex, grades)\n",
    "\n",
    "UNETR --> 6 features (age, sex, grades)"
   ],
   "metadata": {
    "id": "5mrdr78--gqD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Single testing"
   ],
   "metadata": {
    "id": "GRQgCY5L8T5V"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL = 'DenseNet'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = f'models/{MODEL.lower()}_{NUM_EPOCHS}.pth'\n",
    "model_name = f'models/densenet_100.pth'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    MODEL,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    feature_dim=feature_dim,\n",
    "    config=config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loader      = model.test_dataloader(test_imgs, test_labels, test_feature_vector)\n",
    "gm_test_loader   = model.test_dataloader(gm_test_imgs, gm_test_labels, gm_test_features)\n",
    "tcia_test_loader = model.test_dataloader(tcia_test_imgs, tcia_test_labels, tcia_test_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9lVOCHcXgjr"
   },
   "outputs": [],
   "source": [
    "eval_model = load_model(model, model_name)\n",
    "\n",
    "metrics, report = test_model(fabric, eval_model, test_loader)\n",
    "wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH0zXIB2LNsB"
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multiple testing"
   ],
   "metadata": {
    "id": "g6hpBnPk8XQl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "MODELS = ['DenseNet', 'HighResNet', 'AttentionUnet', 'VitAutoEnc', 'UNETR']"
   ],
   "metadata": {
    "id": "oRPJHHZQsIBy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "results = dict.fromkeys(MODELS, {})\n",
    "\n",
    "for model_name in MODELS:\n",
    "    st = time.time()\n",
    "    wandb.init(project=\"idh-status\", name=f'{model_name}_test')\n",
    "    print(f'Evaluating {model_name}...')\n",
    "\n",
    "    ckpt_name  = f'models/{model_name.lower()}.pth'\n",
    "    model = get_model(\n",
    "        model_name,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        feature_dim=feature_dim,\n",
    "        config=config\n",
    "    )\n",
    "    test_loader = model.test_dataloader(test_imgs, test_labels, test_feature_vector)\n",
    "    # test_loader = model.test_dataloader(gm_test_imgs, gm_test_labels, gm_test_features)  # GM\n",
    "    # test_loader = model.test_dataloader(tcia_test_imgs, tcia_test_labels, tcia_test_features)  # TCIA\n",
    "    eval_model = load_model(model, ckpt_name)\n",
    "    metrics, report = test_model(fabric, eval_model, test_loader)\n",
    "    # wandb.log(metrics)\n",
    "    results[model_name]['metrics'] = metrics\n",
    "    results[model_name]['report'] = report\n",
    "    wandb.finish()\n",
    "\n",
    "    seconds = time.time() - st\n",
    "    print(f'Elapsed time {seconds} seconds')\n",
    "    print(f'No. images per second {len(test_loader) / seconds} seconds')"
   ],
   "metadata": {
    "id": "V-Vzzt9rsN1I"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
